---
title: 성공과 실패를 결정하는 1%의 네트워크 원리 5장
uploadDate: 2022년 10월 06일
description: 성공과 실패를 결정하는 1%의 네트워크 원리를 읽은 후 내용을 정리한 블로그입니다. 차례는 그대로 따라가나 저의 말로 풀어서 정리할 예정입니다. 최대한 책 내용을 따라가나 중간중간 개인적인 생각이 포함될 수 있습니다.
---

이번 장은 서버 측 LAN에서 실제로 동작을 수행하는 웹서버까지 도달하는 여정을 서술한다. 생각보다 실제 웹서버로 요청이 전달되기까지 여러 곳을 거치는데 이번 장에서는 크게 방화벽, 부하분산, 캐시서버, CDN을 다룬다. 데브옵스에 조금이라도 관심이 있다면 다들 한번 즘 들어봤을 주제라 크게 어렵지 않았다.



### 01. 웹 서버의 설치 장소

* 사내 LAN에 웹서버를 설치하는 방식은 1. 웹서버로 접근하는 패킷을 막지 못하고 2.사내 LAN의 다른 컴퓨터들 모두 public IP가 필요하기에 쓰지 않는다. 지금은 인터넷과 접속하는 문 앞에 방화벽을 설치하여 사내 LAN과 웹 서버가 존재하는 공개 서버용 LAN을 분리하고 방화벽이 직접 패킷을 중개하는 방식을 사용한다.
* 돈 좀 있는 회사는 IX나 NOC의 데이터 센터에 서버를 구축한다. 아무래도 통신 속도가 짱짱한 곳이고 통신의 핫플레이스이니 만큼 이런 곳에 서버를 설치하면 빠른 속도를 체감할 수 있다.



### 02. 방화벽의 원리와 동작

* 네트워크에 흐르는 수많은 패킷을 검사하고 알맞은 목적지를 정해서 보내는 작업은 생각보다 힘들다. 자칫하면 패킷을 검사하고 분석하느라 성능이 드라마틱하게 갈려나갈 수 있다. 여러 방식이 있지만 성능, 가격, 사용성 등의 이유로 패킷 필터링형이 가장 널리 보급되어 있다고 하니 이를 알아보도록 하자. (개인적으로 패킷 필터링형이 가장 만만해서 고른 듯싶다.)
* 패킷 필터링 방식은 사전에 룰을 정하고 들어오는 패킷을 분석해서 해당 룰을 통과하는 패킷만 통과시키는 방식이다. 다양한 룰이 있지만 이 중 많이 쓰이는 룰만 보도록 하자.
  1. 웹서버에서 외부로 접속 요청을 보내는 패킷은 거른다. (송신처 IP와 TCP의 SYN, ACK 검사)
  2. 웹서버로 오는 패킷에 포트 번호를 검사해 특정 포트가 아니면 거른다. (서비스를 진행하는 포트 몇 개만 허용한다.)
  3. ICMP 메세지 중 ping의 경우 공격자가 네트워크 구조를 파악하기 위해 쓰는 경우도 있다. 그래서 네트워크의 구조를 숨기기 위해 ICMP의 몇몇 유형을 금지할 수 있다.
* 방화벽은 보통 시점과 종점을 조사한다. 그래서 모든 보안 위협을 막아주진 않는다. 내부 패킷을 분석해 위험한 데이터가 있는지 확인하는 방식도 있지만 이 방식도 웹 서버의 결함으로 인한 보안 취약점은 막아줄 수 없다. 그래도 보안의 모토가 완벽함보단 최선을 추구함이기에 방화벽이 없는 것보단 훨씬 낫다.



### 03. 복수 서버에 리퀘스트를 분배한 서버의 부하 분산

**scale up** : 하나의 장비(서버)의 성능을 올리는 방식, 한계점이 명확하다.
**scale out** : 하나의 서버를 여러 서버로 대체하는 방식, 성능을 넣은 기계만큼 확장시킬 수 있지만 하나가 여러 개가 되었기 때문에 조치가 필요하다.

* 처리 능력이 부족해지면 하나의 장비를 업그레이드하는 방식으로는 부족해질 수 있다. 이에 그냥 여러 개의 서버를 사용해 처리를 분담하는 방식이 사용되었는데 이러한 처리 방법을 통틀어 분산 처리라고 한다.

* 가장 간단하게 리퀘스트를 서버 개수만큼 나누어서 처리하는 방식이 있다. 이 경우 DNS 서버에서 여러 개의 IP를 돌려주는데 이때 리퀘스트에 따라 IP 순서를 하나씩 바꿔가며 응답한다. 원형 큐와 같은 방식으로 돌아가기에 이를 **라운드 로빈**이라고 한다. 브라우저는 이 주소를 받아 순서대로 웹서버에 응답을 요청한다.

  > 192.0.2.60 - 192.0.2.70 - 192.0.2.80
  > 192.0.2.70 - 192.0.2.80 - 192.0.2.60
  > 192.0.2.80 - 192.0.2.60 - 192.0.2.70

  다만 DNS와 브라우저로 부하 분산을 구동시키는 경우 stateless하지 않은 요청은 대처할 수 없다. (그냥 패킷을 무작위로 공평하게 나눈다.) 

* 라운드 로빈은 부하 분산이 랜덤으로 배분된다는 단점이 있기 때문에 **부하 분산 장치** 혹은 **로드 밸런서**라는 장비를 사용해 부하 분산을 하기 시작했다. 먼저 DNS에 자신의 웹 서버 주소 대신 부하 분산 장치의 주소를 등록한다. 그럼 이제 클라이언트에서 오는 요청을 부하 분산 장치에서 전부 받게 되고 이 장치에서 어느 서버로 보낼지 결정한다.

  단순 액세스의 경우에는 웹 서버의 부하 상태를 근거로 요청을 분산시킨다. 정확하게 웹 서버의 상태를 조회하면 좋겠지만 이 또한 부하이기 때문에 밸런스를 잘 맞추는 게 중요하다. 

  원래 HTTP는 Stateless라 순서가 있는 요청도 HTTP프로토콜 안에서는 전후 관계를 파악할 수 없다. 이게 너무 불편해서 HTTP 스펙에 상태를 남길 수 있는 기능이 추가되었는데 이게 바로 cookie다. 복수 페이지에 걸친 요청의 경우 cookie에 남긴 추가 정보를 이용해 전후 관계를 파악하여 같은 웹 서버에 전송하게 한다.



### 04. 캐시 서버를 이용한 서버의 부하 분산

**프록시** : 웹 서버와 클라이언트 사이에 요청을 중계하는 역할을 담당하는 서버

부하 분산에는 같은 기능을 하는 서버를 여러 개 두는 방식도 있지만 웹 서버가 하는 일을 여러 역할로 나누어서 부하를 분산하는 방식도 있다. 이러한 역할별 분산 처리 방법 중 하나가 캐시 서버를 활용하는 방식이다.

* 웹 서버는 URL 점검, 권한 확인, DB 확인 등등 여러 일을 복합적으로 하기 때문에 단순한 일도 오래 걸리는 편이다. 한편 캐시 서버는 단순히 데이터를 꺼내서 내보내는 기능에 특화되어 있기 때문에 단순 데이터 요청을 웹 서버보다 더 빠르게 처리할 수 있다. 캐시 서버를 사용한다고 해서 웹 서버에 요청이 줄어들지는 않지만 데이터를 꺼내서 보내는 동작을 캐시 서버가 대신 처리해주기에 웹 서버의 부하를 줄일 수 있다.

<img src="/Users/cuzz/Documents/project-github/cuzzs-log/public/posts/network/image/network05_01.png" alt="IX" width="600" height="380" />

* 캐시 서버에 데이터가 없는 경우, Server에 데이터를 요청해서 데이터를 받은 이후 해당 데이터를 Cache 서버에 저장한 후 Client에게 응답한다. 반면 캐시 서버에 데이터가 있는 경우, 원래 서버에게 해당 데이터가 바뀌었는지 여부를 물어본다. 변경된 게 없다면 캐시 서버의 데이터를 클라이언트에게 주고(이때는 Via Header가 없다.) 변경되었다면 캐시 미스가 났을 때와 동일하게 동작한다.

#### 프록시

포워드 프록시 : 브라우저의 URL 분석 과정 없이 모든 요청을 해당 프록시에 전달 => 해당 프록시에서 해당 요청을 어떻게 할지 결정
리버스 프록시 : 포워드 프록시는 브라우저의 설정을 바꾸어야 함 => 브라우저의 설정을 바꾸지 않고도 이를 가능하게 함.
트랜스페이런트 프록시 : IP 주소를 가지고 액세스 대상인 웹서버를 판단하는 방식 => IP를 이용해서 웹서버를 구분하기에 자기 자신을 DNS에 올리면 안 된다. 그래서 모든 패킷이 한 번에 모이는 길목에 설치된다.



### 05. 콘텐츠 배포 서비스

* 웹 서버의 캐시 서버는 웹 서버의 부하를 줄여줄 순 있지만 서버로 오는 네트워크의 트래픽에는 영향을 끼칠 수 없다. 그렇다고 클라이언트 LAN안에 캐시 서버를 두면 네트워크 트래픽 감소 효과를 볼 수 있겠지만 너무 비현실적이다. 그래서 중요한 프로바이더를 선정하고 해당 프로바이더의 핫 플레이스에 캐시 서버를 두어 어느 정도 트래픽 감소 효과를 노리는 전략이 생겨났다. 물론 프로바이더와 계약하여 캐시 서버를 설치하는 것도 일개 회사가 진행하기에는 많이 힘들다. 그래서 이를 대신 해주는 서비스가 등장하였는데 이러한 서비스는 CDS(Content Delivery Service)라고 한다.

* 프로바이더의 캐시 서버들을 제대로 활용하려면 클라이언트의 요청에 가장 가까운 캐시 서버 IP를 알아낼 수 있어야 한다. 하지만 DNS에 캐시 서버의 IP를 여러 개 등록하는 방식의 경우 거리를 계산하지 않고 라운드 로빈으로 무작위 IP를 리턴한다. 이에 최적의 캐시 서버를 찾을 수 있는 로직이 개발되었다.

  1. DNS 시스템을 발전시키자.

     캐시 서버의 IP만 받지 말고 해당 캐시 서버를 중개하는 라우터의 경로 정보 또한 가져온다. 해당 경로 정보를 바탕으로 DNS 요청을 날린 client와 캐시 서버와의 거리를 계산해서 가장 거리가 짧은 캐시 서버의 IP를 리턴한다.
     
  1. 리다이렉트 서버를 이용하자.
  
     DNS에 가장 가까운 캐시 서버 IP를 리턴해주는 리다이렉트 서버 IP를 등록해둔다. 리다이렉트 서버는 사용자와 가장 가까운 캐시 서버를 계산한 이후에  Location 헤더를 통해 사용자에게 가장 가까운 캐시 서버로 리다이렉트하도록 유도한다.
  
* 위에서 말한 캐시 서버의 경우, 캐시 힛인 경우에도 데이터가 최신인지 서버에게 물어보고 서버가 최신 데이터라고 응답해야 데이터를 보내는 매커니즘으로 작동한다. 하지만 CDN은 네트워크 혼잡도를 낮추기 위해서 나온 아인데 이렇게 캐시 힛이 난 경우에도 서버에게 일일이 물어보면 네트워크 혼잡도가 쉽게 낮아지지 않을 것이다. 그래서 CDN의 경우 서버에서 데이터를 업데이트했을 때 이를 즉시 반영하여 항상 최신의 데이터를 가지게 하여 캐시 힛이 났을 경우 그냥 거기서 바로 콘텐츠를 제공하는 방식을 사용한다.



